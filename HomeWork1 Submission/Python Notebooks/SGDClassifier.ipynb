{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL3cBNJ5zTuW",
        "outputId": "ce988b38-8750-4794-db6b-e0684b6d0d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount='True')\n",
        "import pandas as pd\n",
        "import math\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from time import time\n",
        "import scipy.stats as stats\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def datasetprep(sms_spam, sms_spam_test):\n",
        "  sms_spam['SMS'] = sms_spam['SMS'].str.replace('\\W', ' ', regex=True) # Removes punctuation\n",
        "  sms_spam['SMS'] = sms_spam['SMS'].str.lower() # Lowercase\n",
        "  sms_spam_test['SMS'] = sms_spam_test['SMS'].str.replace('\\W', ' ', regex=True) # Removes punctuation\n",
        "  sms_spam_test['SMS'] = sms_spam_test['SMS'].str.lower() # Lowercase\n",
        "  vocabulary = []\n",
        "  for sms in sms_spam['SMS']:\n",
        "    for word in sms:\n",
        "        vocabulary.append(word)\n",
        "  vocabulary = list(set(vocabulary)) # Gives Unique Vocabulary\n",
        "\n",
        "  bernoulli = {unique_word: [0] * len(sms_spam['SMS']) for unique_word in vocabulary}\n",
        "  bow = {unique_word: [0] * len(sms_spam['SMS']) for unique_word in vocabulary}\n",
        "\n",
        "  for index, sms in enumerate(sms_spam['SMS']):\n",
        "    for word in sms:\n",
        "        bow[word][index] += 1\n",
        "        if bernoulli[word][index] == 0:\n",
        "          bernoulli[word][index] += 1\n",
        "\n",
        "  word_counts = pd.DataFrame(bernoulli)\n",
        "  bernoulli_clean = pd.concat([sms_spam, word_counts], axis=1)\n",
        "  word_counts = pd.DataFrame(bow)\n",
        "  bow_clean = pd.concat([sms_spam, word_counts], axis=1)\n",
        "  return bernoulli_clean, bow_clean\n",
        "\n",
        "def classifier(sms_spam, sms_spam_test, model_type):\n",
        "  bernoulli, bow = datasetprep(sms_spam,sms_spam_test)\n",
        "  vec = CountVectorizer(stop_words='english')\n",
        "  if model_type == 'bernoulli':\n",
        "    X_train = vec.fit_transform(bernoulli['SMS']) \n",
        "    y_train = bernoulli['Label']\n",
        "    X_test = vec.transform(sms_spam_test['SMS']) \n",
        "    y_test = sms_spam_test['Label']\n",
        "  elif model_type == 'bow':\n",
        "    X_train = vec.fit_transform(bow['SMS']) \n",
        "    y_train = bow['Label']\n",
        "    X_test = vec.transform(sms_spam_test['SMS']) \n",
        "    y_test = sms_spam_test['Label']\n",
        "  return X_train, y_train, X_test, y_test \n",
        "\n",
        "def model(alpha, eta0, learning_rate, loss, max_iter,penalty, tol, sms_spam, sms_spam_test, model_type):\n",
        "  X_train, y_train, X_test, y_test = classifier(sms_spam, sms_spam_test, model_type)\n",
        "  sgd = SGDClassifier(alpha = alpha, eta0 = eta0, learning_rate = learning_rate, loss=loss, max_iter = max_iter, penalty = penalty, tol = tol)\n",
        "  sgd.fit(X_train, y_train);\n",
        "  sgd.score(X_test, y_test)\n",
        "  prediction = sgd.predict(X_test)\n",
        "  print('Accuracy:', accuracy_score(y_test, prediction))\n",
        "  print('Precision:', precision_score(y_test, prediction, pos_label='spam'))\n",
        "  print('Recall:', recall_score(y_test, prediction, pos_label='spam'))\n",
        "  print('F1 score:', f1_score(y_test, prediction, pos_label='spam'))\n",
        "\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\n",
        "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                    results[\"mean_test_score\"][candidate],\n",
        "                    results[\"std_test_score\"][candidate],\n",
        "                )\n",
        "            )\n",
        "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "def parameter_tuning(sms_spam, sms_spam_test, model_type):\n",
        "  X_train, y_train, X_test, y_test = classifier(sms_spam, sms_spam_test, model_type)\n",
        "  sgd = SGDClassifier()\n",
        "  sgd.fit(X_train, y_train)\n",
        "  sgd.score(X_test, y_test)\n",
        "  param_grid = {'alpha': (0.01, 0.02, 0.03, 0.04, 0.05),\n",
        "                              'max_iter': (range(500, 3000, 1000)),\n",
        "                              'learning_rate': ('optimal', 'invscaling', 'adaptive'),\n",
        "                              'eta0': (0.3, 0.7),\n",
        "                              'tol': (0.001, 0.005),\n",
        "                              'penalty': ('l1','l2'),\n",
        "                              'loss': ('log', 'ridge', 'hinge')\n",
        "                              }\n",
        "  grid_search = GridSearchCV(sgd, param_grid=param_grid)\n",
        "  start = time()\n",
        "  grid_search.fit(X_train, y_train)\n",
        "  print(\n",
        "      \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
        "  )\n",
        "\n",
        "  report(grid_search.cv_results_) "
      ],
      "metadata": {
        "id": "8XIyHSmfz_j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Enron1 \n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron1train.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron1test.csv', header=None, names=['Label', 'SMS'])\n",
        "\n",
        "# Before Tuning \n",
        "# Accuracy = 94.298\n",
        "# After Parameter Tuning\n",
        "# Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'optimal', 'loss': 'log', 'max_iter': 500, 'penalty': 'l2', 'tol': 0.005}\n",
        "model(alpha = 0.01, eta0 = 0.3, learning_rate = 'optimal', loss=\"log\", max_iter = 500, penalty = 'l2', tol = 0.005,\n",
        "      sms_spam = sms_spam, sms_spam_test = sms_spam_test, model_type = 'bernoulli')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmDbKOs70VN6",
        "outputId": "60525ad7-f254-4998-bf1b-bb8b25660286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9539473684210527\n",
            "Precision: 0.9\n",
            "Recall: 0.9664429530201343\n",
            "F1 score: 0.9320388349514563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bow Enron1 \n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron1train.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron1test.csv', header=None, names=['Label', 'SMS'])\n",
        "\n",
        "# Before Tuning \n",
        "# Accuracy = 93.640\n",
        "# After Parameter Tuning\n",
        "# Parameters: {'alpha': 0.03, 'eta0': 0.7, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1500, 'penalty': 'l2', 'tol': 0.001}\n",
        "model(alpha = 0.03, eta0 = 0.7, learning_rate = 'optimal', loss=\"hinge\", max_iter = 1500, penalty = 'l2', tol = 0.001,\n",
        "      sms_spam = sms_spam, sms_spam_test = sms_spam_test, model_type = 'bow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxPnoG1p0tL1",
        "outputId": "053c3ca3-fd39-4646-dfa4-faf6ad4c0772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9495614035087719\n",
            "Precision: 0.8841463414634146\n",
            "Recall: 0.9731543624161074\n",
            "F1 score: 0.926517571884984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Enron4\n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron4train.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron4test.csv', header=None, names=['Label', 'SMS'])\n",
        "\n",
        "# Before Tuning \n",
        "# Accuracy = 93.186\n",
        "# After Parameter Tuning\n",
        "# Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 1500, 'penalty': 'l2', 'tol': 0.005}\n",
        "model(alpha = 0.01, eta0 = 0.3, learning_rate = 'adaptive', loss=\"hinge\", max_iter = 1500, penalty = 'l2', tol = 0.005,\n",
        "      sms_spam = sms_spam, sms_spam_test = sms_spam_test, model_type = 'bow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdQt4_gT8Ulb",
        "outputId": "5445f66a-091a-4c29-fd4d-2f5b2374a9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9576427255985267\n",
            "Precision: 0.9444444444444444\n",
            "Recall: 1.0\n",
            "F1 score: 0.9714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bow Enron4\n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron4train.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/enron4test.csv', header=None, names=['Label', 'SMS'])\n",
        "\n",
        "# Before Tuning \n",
        "# Accuracy = 94.475\n",
        "# After Parameter Tuning\n",
        "#Parameters: {'alpha': 0.02, 'eta0': 0.7, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 1500, 'penalty': 'l2', 'tol': 0.001}}\n",
        "model(alpha = 0.02, eta0 = 0.7, learning_rate = 'adaptive', loss=\"hinge\", max_iter = 1500, penalty = 'l2', tol = 0.001,\n",
        "      sms_spam = sms_spam, sms_spam_test = sms_spam_test, model_type = 'bow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfdokRIO8Pq5",
        "outputId": "3ae26fed-4118-46aa-81d5-29e9325238bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9558011049723757\n",
            "Precision: 0.9421686746987952\n",
            "Recall: 1.0\n",
            "F1 score: 0.9702233250620347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli HW\n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/hwtrain.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/hwtest.csv', header=None, names=['Label', 'SMS'])\n",
        "\n",
        "# Before Tuning \n",
        "# Accuracy = 93.933\n",
        "# After Parameter Tuning\n",
        "# Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 500, 'penalty': 'l2', 'tol': 0.001}\n",
        "model(alpha = 0.01, eta0 = 0.3, learning_rate = 'adaptive', loss=\"hinge\", max_iter = 500, penalty = 'l2', tol = 0.001,\n",
        "      sms_spam = sms_spam, sms_spam_test = sms_spam_test, model_type = 'bernoulli')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxPWC1iD-oL7",
        "outputId": "819911c2-db87-412b-c369-f6e706d1bc8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9497907949790795\n",
            "Precision: 0.9015151515151515\n",
            "Recall: 0.9153846153846154\n",
            "F1 score: 0.9083969465648855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bow HW\n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/hwtrain.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/hwtest.csv', header=None, names=['Label', 'SMS'])\n",
        "\n",
        "# Before Tuning \n",
        "# Accuracy = 93.514\n",
        "# After Parameter Tuning\n",
        "#Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 2500, 'penalty': 'l2', 'tol': 0.005}\n",
        "model(alpha = 0.01, eta0 = 0.3, learning_rate = 'adaptive', loss=\"hinge\", max_iter = 2500, penalty = 'l2', tol = 0.005,\n",
        "      sms_spam = sms_spam, sms_spam_test = sms_spam_test, model_type = 'bow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqPvWfC0_i7n",
        "outputId": "5b2d07ee-fc43-4d7d-a74f-0b5af0692108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9497907949790795\n",
            "Precision: 0.9076923076923077\n",
            "Recall: 0.9076923076923077\n",
            "F1 score: 0.9076923076923076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Tuning\n",
        "# Import Datasets\n",
        "sms_spam = pd.read_csv('/content/drive/MyDrive/Datasets/ML/hwtrain.csv', header=None, names=['Label', 'SMS'])\n",
        "sms_spam_test = pd.read_csv('/content/drive/MyDrive/Datasets/ML/hwtest.csv', header=None, names=['Label', 'SMS'])\n",
        "model_type = 'bernoulli'  # Can be bernoulli or bow\n",
        "parameter_tuning(sms_spam, sms_spam_test, model_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ1rJsck3KNt",
        "outputId": "3dff7a3c-5d11-40c0-f3eb-882d53540bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV took 34.59 seconds for 1080 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.950 (std: 0.021)\n",
            "Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 2500, 'penalty': 'l2', 'tol': 0.005}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.948 (std: 0.017)\n",
            "Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 500, 'penalty': 'l2', 'tol': 0.001}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.948 (std: 0.014)\n",
            "Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1500, 'penalty': 'l2', 'tol': 0.001}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.948 (std: 0.016)\n",
            "Parameters: {'alpha': 0.01, 'eta0': 0.3, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 2500, 'penalty': 'l2', 'tol': 0.001}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.948 (std: 0.011)\n",
            "Parameters: {'alpha': 0.03, 'eta0': 0.7, 'learning_rate': 'adaptive', 'loss': 'hinge', 'max_iter': 1500, 'penalty': 'l2', 'tol': 0.005}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1800 fits failed out of a total of 5400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1800 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 892, in fit\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 649, in _fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 162, in _validate_params\n",
            "    raise ValueError(\"The loss %s is not supported. \" % self.loss)\n",
            "ValueError: The loss ridge is not supported. \n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.88541374 0.87896213 0.93733053 ... 0.81217859 0.92435718 0.93083216]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJjP3ejz-GuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}